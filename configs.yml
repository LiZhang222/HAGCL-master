corafull:
  mini_batch: 64
  num_neighbor: [10]
  lr: 0.01
  weight_decay: 5e-4
  max_epoch: 4
  mask_rate: 0.5
  drop_edge_rate: 0.5
  sim: 50
  std: 20
  cov: 5
  encoder: fagcn
  decoder: fagcn
  lr_f: 0.01
  num_hidden: 1024
  num_proj_hidden: 512
  alpha_0: 0.3
  gamma: 1.0
  alpha_T: 1.0
  belta: 0.5
  belta_edge: 0.5
  mlp: '512-512-512'
  num_heads: 2
  num_layers: 2
  weight_decay_f: 1e-4
  mask_encoder: gat
  max_epoch_f: 1000
  activation: prelu
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True
cora:
  dropmessage: 0
  drop_out: 0.5
  layer_dropout: 0.3
  lr: 0.003
  add_edge_rate: 0.4
  weight_decay: 6e-4
  max_epoch: 600
  mask_rate: 0.3
  drop_edge_rate: 0
  sim: 5
  std: 20
  cov: 1
  encoder: fagcn
  decoder: fagcn
  lr_f: 0.04
  num_hidden: 1024
  num_proj_hidden: 512
  alpha_0: 0.1
  gamma: 1.0
  alpha_T: 1.0
  belta: 0.4
  belta_edge: 1.0
  mlp: '512-512-512'
  num_heads: 4
  num_layers: 2
  weight_decay_f: 1e-4
  mask_encoder: gat
  max_epoch_f: 500
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True
citeseer:
  dropmessage: 0
  drop_out: 0.5
  layer_dropout: 0.5
  add_edge_rate: 0.1
  lr: 0.0005
  lr_f: 0.01
  num_hidden: 1024
  num_proj_hidden: 512
  num_heads: 2
  num_layers: 2
  weight_decay: 5e-4
  weight_decay_f: 0.01
  mask_encoder: gat
  max_epoch: 400
  mask_rate: 0.1
  drop_edge_rate: 0.2
  belta: 1.0
  belta_edge: 1.0
  sim: 15
  std: 10
  cov: 5
  alpha_0: 0.9
  gamma: 1
  alpha_T: 1
  mlp: '512-512'
  encoder: fagcn
  decoder: fagcn
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 1
  scheduler: True
  max_epoch_f: 600
pubmed:
  layer_dropout: 0.3
  lr: 0.003
  weight_decay: 2e-5
  max_epoch: 3000
  mask_rate: 0.5
  drop_edge_rate: 0.5
  sim: 10
  std: 10
  cov: 1
  num_hidden: 128
  num_proj_hidden: 128
  alpha_0: 0.8
  gamma: 1.0
  alpha_T: 1.0
  belta: 0.5
  belta_edge: 0.5
  mlp: "128-128-128"
  lr_f: 0.01
  num_heads: 4
  num_layers: 3
  weight_decay_f: 1e-4
  max_epoch_f: 300
  encoder: fagcn
  decoder: fagcn
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.0
  alpha_l: 3
  scheduler: True
  mask_encoder: gat
photo:
  layer_dropout: 0.2
  lr: 0.005
  lr_f: 0.01
  weight_decay: 1e-5
  max_epoch: 2000
  mask_rate: 0.1
  drop_edge_rate: 0.9
  sim: 5
  std: 20
  cov: 1
  num_hidden: 256
  num_proj_hidden: 256
  alpha_0: 0.1
  gamma: 1.0
  alpha_T: 1.0
  belta: 0.00001
  belta_edge: 0.00001
  mlp: "256-256-256"
  num_heads: 4
  num_layers: 2
  weight_decay_f: 1e-4
  max_epoch_f: 300
  encoder: fagcn
  decoder: fagcn
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.0
  alpha_l: 3
  scheduler: True
  mask_encoder: gat
CS:
  lr: 0.05
  lr_f: 0.01
  weight_decay: 1e-5
  max_epoch: 2000
  mask_rate: 0.4
  drop_edge_rate: 0.7
  sim: 1
  std: 5
  cov: 0
  belta: 0.8
  belta_edge: 0.4
  num_hidden: 128
  num_proj_hidden: 64
  alpha_0: 0.5
  gamma: 1.0
  alpha_T: 1.0
  mlp: "64-64-64"
  num_heads: 4
  num_layers: 1
  weight_decay_f: 1e-4
  max_epoch_f: 300
  encoder: fagcn
  decoder: gat
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.0
  alpha_l: 3
  scheduler: True
  mask_encoder: gat
squirrel:
  drop_out: 0.5
  dropmessage: 0.2
  add_edge_rate: 0.1
  layer_dropout: 0.3
  lr: 0.01
  weight_decay: 5e-5
  max_epoch: 2000
  mask_rate: 0.5
  drop_edge_rate: 0.2
  sim: 10
  std: 0
  cov: 1
  encoder: m_fagcn
  fagcn_heads: 3
  concat: False
  decoder: gat
  lr_f: 0.01
  num_hidden: 128
  num_proj_hidden: 64
  alpha_0: 0.4
  gamma: 1.0
  alpha_T: 1.0
  belta: 0.1
  belta_edge: 0.7
  mlp: '64-64'
  num_heads: 4
  num_layers: 2
  weight_decay_f: 5e-5
  mask_encoder: gat
  max_epoch_f: 1500
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True
chameleon:
  dropmessage: 0
  add_edge_rate: 0
  layer_dropout: 0.2
  lr: 0.01
  weight_decay: 5e-5
  max_epoch: 1500
  mask_rate: 0.2
  drop_edge_rate: 0.2
  sim: 10
  std: 0
  cov: 25
  encoder: m_fagcn
  fagcn_heads: 2
  concat: False
  decoder: gat
  lr_f: 0.01
  num_hidden: 1024
  num_proj_hidden: 512
  alpha_0: 0.2
  gamma: 1.0
  alpha_T: 1.0
  belta: 0.8
  belta_edge: 1.0
  mlp: '512-512'
  num_heads: 4
  num_layers: 1
  weight_decay_f: 5e-5
  mask_encoder: gat
  max_epoch_f: 1200
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True
actor:
  drop_out: 0.4
  dropmessage: 0.8
  add_edge_rate: 0.2
  layer_dropout: 0.1
  lr: 0.001
  lr_f: 0.03
  weight_decay: 0.005
  weight_decay_f: 0.0001
  max_epoch: 400
  max_epoch_f: 800
  mask_rate: 0.3
  drop_edge_rate: 0.3
  belta: 1.0
  belta_edge: 1.0
  sim: 30
  std: 1
  cov: 5
  encoder: m_fagcn
  fagcn_heads: 2
  concat: False
  decoder: gat
  num_hidden: 1024
  num_proj_hidden: 512
  alpha_0: 0.1
  gamma: 1.0
  alpha_T: 0.4
  mlp: '512-512'
  num_heads: 4
  num_layers: 2
  mask_encoder: gat
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True
squirrel-filtered:
  drop_out: 0
  dropmessage: 0.8
  add_edge_rate: 0
  layer_dropout: 0.3
  lr: 0.01
  weight_decay: 0.05
  max_epoch: 20
  mask_rate: 0.7
  drop_edge_rate: 0.2
  sim: 10
  std: 5
  cov: 1
  encoder: m_fagcn
  fagcn_heads: 4
  concat: False
  decoder: fagcn
  lr_f: 0.03
  num_hidden: 256
  num_proj_hidden: 16
  alpha_0: 0.3
  gamma: 1.0
  alpha_T: 0.4
  belta: 0.1
  belta_edge: 0.4
  mlp: '256-256'
  num_heads: 4
  num_layers: 2
  weight_decay_f: 0.0001
  mask_encoder: gat
  max_epoch_f: 200
  in_drop: 0
  attn_drop: 0
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True
chameleon-filtered:
  drop_out: 0
  dropmessage: 0.4
  add_edge_rate: 0.3
  layer_dropout: 0.5
  lr: 0.0001
  lr_f: 0.05
  max_epoch: 20
  max_epoch_f: 200
  weight_decay: 0.0001
  weight_decay_f: 0.0001
  belta: 0.8
  belta_edge: 0.6
  mask_rate: 0.2
  drop_edge_rate: 0.2
  sim: 1
  std: 30
  cov: 10
  encoder: m_fagcn
  fagcn_heads: 2
  concat: False
  decoder: mlp
  num_hidden: 1024
  num_proj_hidden: 64
  alpha_0: 0.3
  gamma: 1.0
  alpha_T: 0.4
  mlp: '64-64'
  num_heads: 4
  num_layers: 1
  mask_encoder: gat
  in_drop: 0.2
  attn_drop: 0.1
  linear_prob: True
  replace_rate: 0.05
  alpha_l: 3
  scheduler: True